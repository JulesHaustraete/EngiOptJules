"""Evaluation for the CGAN 1D."""

from __future__ import annotations

import argparse
import dataclasses
import os

from engibench.utils.all_problems import BUILTIN_PROBLEMS
from gymnasium import spaces
import numpy as np
import pandas as pd
import torch as th

from engiopt import metrics
from engiopt.cgan_1d.cgan_1d import Generator
from engiopt.cgan_1d.cgan_1d import prepare_data
from engiopt.dataset_sample_conditions import sample_conditions
import wandb


@dataclasses.dataclass
class Args:
    """Command-line arguments."""

    problem_id: str = "airfoil"
    """Problem identifier."""
    seed: int = 1
    """Random seed to run."""
    wandb_project: str = "engiopt"
    """Wandb project name."""
    wandb_entity: str | None = None
    """Wandb entity name."""
    n_samples: int = 3
    """Number of generated samples per seed."""
    sigma: float = 10.0
    """Kernel bandwidth for MMD and DPP metrics."""
    output_csv: str = "cgan_1d_{problem_id}_metrics.csv"
    """Output CSV path template; may include {problem_id}."""


def parse_args() -> Args:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Evaluate CGAN 1D model")
    
    parser.add_argument("--problem-id", default="airfoil", help="Problem identifier")
    parser.add_argument("--seed", type=int, default=1, help="Random seed")
    parser.add_argument("--wandb-project", default="engiopt", help="Wandb project name")
    parser.add_argument("--wandb-entity", default=None, help="Wandb entity name")
    parser.add_argument("--n-samples", type=int, default=3, help="Number of generated samples")
    parser.add_argument("--sigma", type=float, default=10.0, help="Kernel bandwidth for MMD and DPP")
    parser.add_argument("--output-csv", default="cgan_1d_{problem_id}_metrics.csv", help="Output CSV path")
    
    parsed_args = parser.parse_args()
    
    return Args(
        problem_id=parsed_args.problem_id,
        seed=parsed_args.seed,
        wandb_project=parsed_args.wandb_project,
        wandb_entity=parsed_args.wandb_entity,
        n_samples=parsed_args.n_samples,
        sigma=parsed_args.sigma,
        output_csv=parsed_args.output_csv,
    )


if __name__ == "__main__":
    args = parse_args()

    seed = args.seed
    problem = BUILTIN_PROBLEMS[args.problem_id]()
    problem.reset(seed=seed)

    # Seeding for reproducibility
    th.manual_seed(seed)
    rng = np.random.default_rng(seed)
    th.backends.cudnn.deterministic = True

    # Select device
    if th.backends.mps.is_available():
        device = th.device("mps")
    elif th.cuda.is_available():
        device = th.device("cuda")
    else:
        device = th.device("cpu")

    if isinstance(problem.design_space, spaces.Box):
        design_shape = problem.design_space.shape
    else:
        dummy_design, _ = problem.random_design()
        design_shape = spaces.flatten(problem.design_space, dummy_design).shape

    ### Set up testing conditions ###
    conditions_tensor, sampled_conditions, sampled_designs_np, _ = sample_conditions(
        problem=problem,
        n_samples=args.n_samples,
        device=device,
        seed=seed,
    )
    # sampled_designs is from a real dataset, not generated by the CGAN

    ### Set Up Generator ###
    if args.wandb_entity is not None:
        artifact_path = f"{args.wandb_entity}/{args.wandb_project}/{args.problem_id}_cgan_1d_generator:seed_{seed}"
    else:
        artifact_path = f"{args.wandb_project}/{args.problem_id}_cgan_1d_generator:seed_{seed}"

    api = wandb.Api()
    artifact = api.artifact(artifact_path, type="model")

    class RunRetrievalError(ValueError):
        def __init__(self):
            super().__init__("Failed to retrieve the run")

    run = artifact.logged_by()
    if run is None or not hasattr(run, "config"):
        raise RunRetrievalError

    artifact_dir = artifact.download()
    ckpt_path = os.path.join(artifact_dir, "generator.pth")
    ckpt = th.load(ckpt_path, map_location=device)

    _, conds_normalizer, design_normalizer = prepare_data(problem, device)

    model = Generator(
        latent_dim=run.config["latent_dim"],
        n_conds=len(problem.conditions),
        design_shape=design_shape,
        design_normalizer=design_normalizer,
        conds_normalizer=conds_normalizer,
    ).to(device)
    model.load_state_dict(ckpt["generator"])
    model.eval()

    # Sample noise and generate designs
    z = th.randn((args.n_samples, run.config["latent_dim"]), device=device)
    
    # gen_designs is generate by the cgan1d with the sampled conditions (Mach number, Reynolds number, etc.)
    gen_designs = model(z, conditions_tensor)
    gen_designs_np = gen_designs.detach().cpu().numpy()
    print(gen_designs_np.shape)

    print("\n=== SIMPLE SIMULATION TEST (FAILURE RATIO) ===")
    fail_ratio = metrics.simulate_failure_ratio(
        problem=problem,
        gen_designs=gen_designs_np,
        sampled_conditions=sampled_conditions,
    )
    print(f"Failure ratio: {fail_ratio}")

    # Simple MMD and DPP calculations without complex processing
    print("\n=== BASIC SHAPE METRICS ===")
    
    # Prepare designs for MMD calculation
    gen_designs_for_metrics = gen_designs_np[:, 1:]  # Remove angle of attack
    sampled_designs_for_metrics = np.array([d["coords"] for d in sampled_designs_np], dtype=np.float32)
    
    # Flatten to 2D for metrics
    gen_designs_flat = gen_designs_for_metrics.reshape(len(gen_designs_for_metrics), -1)
    sampled_designs_flat = sampled_designs_for_metrics.reshape(len(sampled_designs_for_metrics), -1)
    
    print(f"Generated designs shape: {gen_designs_flat.shape}")
    print(f"Dataset designs shape: {sampled_designs_flat.shape}")

    # Calculate basic metrics
    mmd_value = metrics.mmd(gen_designs_flat, sampled_designs_flat, sigma=args.sigma)
    dpp_value = metrics.dpp_diversity(gen_designs_flat, sigma=args.sigma)
    
    print(f"MMD: {mmd_value}")
    print(f"DPP diversity: {dpp_value}")

    # Create simple results
    results_dict = {
        "problem_id": args.problem_id,
        "model_id": "cgan_1d",
        "seed": seed,
        "n_samples": args.n_samples,
        "fail_ratio": fail_ratio,
        "mmd": mmd_value,
        "dpp": dpp_value,
    }
    
    metrics_df = pd.DataFrame(results_dict, index=[0])
    out_path = args.output_csv.format(problem_id=args.problem_id)
    write_header = not os.path.exists(out_path)
    metrics_df.to_csv(out_path, mode="a", header=write_header, index=False)

    print(f"Seed {seed} done; appended to {out_path}")
